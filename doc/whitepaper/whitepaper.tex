% -*- mode: LaTeX-mode; eval: (visual-line-mode t); -*-
\documentclass[letterpaper]{article}

\usepackage[a4paper, margin=1in, top=1cm]{geometry} % Adjust top margin
\usepackage{listings}
\lstset{%
  basicstyle=\ttfamily\small,
  keywordstyle=\bfseries,
  columns=fullflexible,
  morekeywords={elim,by,apply,rewrite},
  frame=single,
  showstringspaces=false
}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{url}
\usepackage{color}
\usepackage{xcolor}
\usepackage{lmodern}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,      % Set to false to disable coloring of links
    linkcolor=black,      % No color for internal links
    urlcolor=black,       % No color for URLs
    pdfborder={0 0 0}     % Remove borders around links
}
\usepackage{fancyhdr} % Load fancyhdr package
\usepackage{datetime}  % Provides formatting options for date  

\pagestyle{fancy} % Enable custom headers/footers
\fancyhf{} % Clear all headers and footers
\renewcommand{\headrulewidth}{0pt} % Removes the horizontal line
\fancyfoot[L]{\today} % Date on the left side of the footer
\fancyfoot[R]{Page \thepage} % Page number on the right side of the footer

\title{Proof Explainer Project \\ \large Advancing Proof Comprehension}
\date{} % Removes date from \maketitle
\author{Vadim Zaliva ~|~ \href{mailto:vadim@zaliva.org}{vadim@zaliva.org}}

\begin{document}

\maketitle
\thispagestyle{fancy}
\section*{The Problem}

Formal proofs using Proof Assistants such as Coq, Lean, and Isabelle
have become important design artefacts of modern high-assurance
software systems. Along with the traditional source code base, proof
scripts must be reviewed, documented, and maintained. As different
groups of proof engineers work on them over time, proof scripts'
documentation and overall readability become crucial.

Unfortunately, proof scripts are generally not easily
human-readable. Consider the following example of a textbook
\cite{mahboubi2021mathematical} proof of Gauss' Formula in Coq, and
compare it with the explanation generated by the LLM, shown in
Appendix~\ref{sec:explained}.

\begin{lstlisting}
Example gauss n :
  \sum_(0 <= i < n.+1) i = n * n.+1 %/ 2.
Proof.
  elim: n =>[|n IHn]; first by apply: big_nat1.
  rewrite big_nat_recr //= IHn addnC -divnMDl //.
  by rewrite mulnS muln1 -addnA -mulSn -mulnS.
Qed.
\end{lstlisting}

The difficulty of human comprehensibility goes beyond the obscure
syntax and is inherent to tactic languages. Each tactic operates on an
implicit proof state, which is invisible unless you step through the
script in the proof assistant. Even if the proof state is available,
it could be large, making it difficult to focus on the relevant part
of each step. Some features of proof assistants allow for writing more
human-readable proofs, but proof writers often ignore them in favour
of brevity and expediency. One example is automatic variable
naming. While tactic languages support some structuring of the proof
script to reflect the branching of the proof tree, these features are
not always rigorously used by human proof writers, and their
expressivity is limited.

\section*{Proposal}

We propose to develop a tool to explain and document Coq proofs with
the help of LLMs. When applied to an already proven lemma, the Proof
Explainer will produce standalone documentation or annotated and
restructured for readability proof script. It could be made accessible
via a simple web interface or integrated into the proof assistant’s
IDE (e.g. as a VS Code plugin). The command line version could be used
in a build or continuous integration process to generate online
documentation or to annotate proof scripts.

It would be immediately helpful to a wide array of users. Professional
proof engineers could use it to examine and understand existing proof
code bases. The generated documentation could be used to onboard new
team members and conduct code reviews. It would immediately benefit
students of formal methods and proof engineering by allowing to break
down and understand the intricacies of existing proofs. It could be an
invaluable educational tool for learning best practices and building
confidence in engaging with real-world proof codebases.

\section*{The approach}

The key observation is that proof explanation requires insight into
the proof state, as maintained by a proof assistant. Our tool will
integrate a proof assistant to access this information. We can use
proof assistant APIs to disambiguate syntax and access the per-step
proof state, definitions, and types. When proof automation is used, we
can unroll the automation steps to access their intermediate results.

The second insight is that current LLMs have a limit on a LLM’s
context window, and feeding the whole proof along with all related
definitions is impractical. This calls for carefully curating the
information supplied to the model at each reasoning step. We can
supply only necessary definitions, strip irrelevant parts of the proof
context, or the calculated proof stated diffs between the steps.

Additionally, we can leverage different models and arbitrage or verify
their results. Using the well-established “AI agents” approach, we can
split reasoning into several steps and process each via separate LLM
queries.

Finally, we can perform multi-pass elaboration for projects containing
reusable lemmas, first processing the auxiliary lemmas and later using
AI-generated summaries of already processed lemmas accessible via
retrieval-augmented generation (RAG) or similar techniques.

In the initial project stage, we would focus first on the Rocq proof
assistant, which is mature and has good automation means (LSP protocol
server, plugin API, and command-line tools). Many Rocq proofs are
published as open source, which we can use for training, testing, and
validation. Our preliminary experiments show that popular LLM models
like OpenAIi o1 and Anthropic Claude 3.5 Sonnet can perform basic Rocq
proof elaboration, which we can use as a baseline.

\section*{Key Differentiators and Related Work}

Several recent projects have used LLMs for formal proofs. For
example,TBD.....  Most attempt to synthesise proofs from scratch or
aid in repairing existing proofs. Given the current early state of
LLMs, these are ambitious goals. We believe that to reach the ultimate
goal of fully automated proof synthesis, merely promoting or guiding
existing models is insufficient, and a deeper integration into the LLM
reasoning process is required, as, for example, proposed in
\cite{park2024grammaraligneddecoding}. [more citations]. The required
approaches would likely be costly, with prices comparable to training
new LLMs. Our goals are more modest, and we are trying to play on the
strength of existing models in knowledge summarisation and
presentation, where they are already showing promising results.

\section*{Budget \& Estimates}

This is a relatively small-scale project. We estimate 6-8 months with
a budget of approximately \$20K, covering the salary of one full-time
research engineer and LLM usage fees. The involvement of the PI (and
potentially a co-PI) is provided at no cost.  References

\pagebreak
\appendix

% generated by ChatGPT o1 model
\section{Appendix: Explained Coq Proof of Gauss's Summation Formula}
\label{sec:explained}
\subsection*{Statement and Proof Script}

\begin{lstlisting}
Example gauss n :
  \sum_(0 <= i < n.+1) i = n * n.+1 %/ 2.
Proof.
  elim: n => [|n IHn]; first by apply: big_nat1.
  rewrite big_nat_recr //= IHn addnC -divnMDl //.
  by rewrite mulnS muln1 -addnA -mulSn -mulnS.
Qed.
\end{lstlisting}

\subsection*{Overall Summary of the Proof}
\begin{itemize}
  \item \textbf{Goal:} Prove that the sum of the first \texttt{n+1} natural numbers 
    \[
      0 + 1 + 2 + \cdots + n 
      = \frac{n(n+1)}{2}.
    \]
  \item \textbf{Approach:} Use induction on \texttt{n}. The base case \texttt{n = 0} follows from 
    a standard library lemma about sums up to \texttt{1}. For the inductive step, 
    the sum \(\sum_{0 \le i < n+2} i\) is split into \(\sum_{0 \le i < n+1} i + (n+1)\). 
    Applying the induction hypothesis and then performing straightforward algebraic 
    rewriting yields the closed-form expression \(\frac{n(n+1)}{2}\).

\end{itemize}

\subsection*{Step-by-Step Explanation}

\begin{enumerate}
  \item \textbf{Induction on n:}
  \begin{lstlisting}
  elim: n => [|n IHn];
  \end{lstlisting}
  This asks Coq to prove the statement by structural induction on \(\texttt{n}\). 
  It generates two subgoals: the base case (when \(\texttt{n} = 0\)) and the 
  inductive step (assuming the statement for \(\texttt{n}\) and proving it for 
  \(\texttt{n+1}\)).
  
  \item \textbf{Base case:} 
  \begin{lstlisting}
  first by apply: big_nat1.
  \end{lstlisting}
  Here, \texttt{big\_nat1} is a lemma from the library that states 
  \(\sum_{0 \le i < 1} i = 0\). This immediately solves the base case, since 
  \(\frac{0 \cdot (0+1)}{2} = 0\).

  \item \textbf{Rewriting the sum:}
  \begin{lstlisting}
  rewrite big_nat_recr //= IHn addnC -divnMDl //.
  \end{lstlisting}
  \texttt{big\_nat\_recr} rewrites the sum 
  \(\sum_{0 \le i < (n+1).+1} i\) into \(\sum_{0 \le i < n+1} i + (n+1)\). 
  The \texttt{//=} notation triggers simplifications. We then apply the induction
  hypothesis \texttt{IHn} (which replaces \(\sum_{0 \le i < n+1} i\) with 
  \(\frac{n(n+1)}{2}\)) and use lemmas like \texttt{addnC} (commutativity of 
  addition) and \texttt{-divnMDl} (rewriting a division expression) to structure 
  the expression.

  \item \textbf{Finishing the algebra:}
  \begin{lstlisting}
  by rewrite mulnS muln1 -addnA -mulSn -mulnS.
  \end{lstlisting}
  These final rewrite steps handle normal algebraic identities in \(\mathbb{N}\), 
  such as distributing multiplication over addition (\(\texttt{mulnS}\)), 
  rearranging sums (\(\texttt{-addnA}\) for associativity), and so forth. 
  After these rewrites, Coq recognises the exact target form \(\frac{n(n+1)}{2}\).

\end{enumerate}

\noindent
Thus, by induction, we conclude that
\[
  \sum_{0 \le i < n+1} i = \frac{n(n+1)}{2},
\]
as required.


\pagebreak
\bibliographystyle{acm}
\bibliography{whitepaper}


\end{document} 

